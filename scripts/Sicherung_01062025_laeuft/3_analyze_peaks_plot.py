#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
3_analyze_peaks_plot.py (V8 - with Surface Informations as lines)
-----------------------
Analyzes track data from a CSV file (generated by 2_parse_gpx_full.py)
to find significant peaks and their associated segments. Calculates
overall and time-based statistics (if time is available). Generates a
detailed elevation profile plot with slope coloring and optional place
annotations. Saves results to separate files.
"""

import sys
import os
import argparse
from dataclasses import dataclass, field
from typing import List, Tuple, Optional, Set, Dict
import time

import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
from matplotlib.collections import LineCollection
from matplotlib.colors import ListedColormap, BoundaryNorm
from matplotlib.patches import Patch
import numpy as np
import pandas as pd
from scipy.signal import savgol_filter, find_peaks
from geopy.distance import distance as geopy_distance
from scipy.spatial import KDTree

# ------------------------------------------------------------
#  Konfigurationsobjekt (ERWEITERT für Orts-Offset)
# ------------------------------------------------------------
@dataclass
class Config:
    # ... (Alle bisherigen Config-Werte) ...
    smooth_window: int = 11
    smooth_poly: int = 2
    gain_threshold: float = 30.0
    eps_height: float = 0.3
    min_peak_prominence_m: float = 40.0
    peak_edge_km: float = 0.25
    plot_dpi: int = 150
    plot_x_tick_major: float = 5.0
    plot_x_tick_minor: float = 1.0
    min_length_draw_m: float = 100.0
    color_fwd_valid_label: str = "#1f77b4"
    color_bwd_valid_label: str = "#2ca02c"
    color_peak1: str = "#ff7f0e"  # Orange
    color_peak2: str = "#9467bd"  # Lila
    color_peak3: str = "#d62728"  # Rot (Beispiel)
    color_peak4: str = "#17becf"  # Cyan (Beispiel)
    peak_highlight_colors: List[str] = field(default_factory=lambda: ["#ff7f0e", "#9467bd", "#d62728", "#17becf"])
    color_fwd_shade: str = "#d6ebf2"
    color_bwd_shade: str = "#d8f0d3"
    shade_alpha: float = 0.4
    color_invalid: str = "#cccccc"
    invalid_alpha: float = 0.20
    slope_thresholds: List[float] = field(default_factory=lambda: [-100, -12, -8, -5, -2, -0.5, 0.5, 2, 5, 8, 12, 100])
    slope_colors: List[str] = field(default_factory=lambda: ['#08306b', '#08519c', '#3182bd', '#9ecae1', '#deebf7','#d9d9d9','#e5f5e0', '#a1d99b', '#fed976', '#fd8d3c', '#e31a1c'])
    slope_labels: List[str] = field(default_factory=lambda: ["<-12%", "-12..-8%", "-8..-5%", "-5..-2%", "-2..-0.5%","Flat","0.5..2%", "2..5%", "5..8%", "8..12%", ">12%"])
    slope_linewidth: float = 2.0
    pause_min_duration_s: float = 120.0
    pause_max_distance_m: float = 5.0
    place_marker_style: str = '^'
    place_marker_color: str = 'darkviolet'
    place_marker_size: int = 8
    place_text_color: str = 'darkviolet'
    place_text_size: int = 7
    place_text_offset_y: int = 12 # Basis-Offset
    place_text_bg_alpha: float = 0.7

    # --- NEU: Konfiguration für dynamischen Y-Offset der Ortslabels ---
    # Distanz-Bins (obere Grenze in Metern)
    place_offset_dist_bins_m: List[float] = field(default_factory=lambda: [100, 300, 600, 1000, 2000])
    # Zusätzlicher Y-Offset (in Plot-Einheiten, also Metern Höhe) für jeden Bin
    # Muss eine Liste mit len(bins)+1 Elementen sein (Wert für <bin[0], bin[0]-bin[1], ..., >bin[-1])
    place_offset_y_additions: List[float] = field(default_factory=lambda: [0, 8, 18, 30, 45, 60])
    # --------------------------------------------------------------------
    # NEU für Oberflächen-Overlay im Plot
    surface_plot_enabled: bool = True # Um es einfach an/auszuschalten
    surface_plot_colors: Dict[str, str] = field(default_factory=lambda: { # Standardfarben, falls nicht aus Config geladen
        "asphalt": "#212529", "paved": "#6c757d", "concrete": "#adb5bd",
        "paving_stones": "#78909C", "sett": "#546E7A", "cobblestone": "#A1887F",
        "compacted": "#795548", "fine_gravel": "#FFCA28", "gravel": "#FF8F00",
        "dirt": "#8D6E63", "ground": "#689F38", "unpaved": "#4E342E",
        "sand": "#FFF176", "grass": "#7CB342", "wood": "#BCAAA4",
        "unknown": "#E0E0E0", "default": "#D32F2F"
    })
    surface_plot_order: List[str] = field(default_factory=lambda: [ # Reihenfolge von unten (einfach) nach oben (schwer)
        "asphalt", "paved", "concrete", "compacted", 
        "fine_gravel", "paving_stones", "sett", "cobblestone",
        "wood", "gravel", "dirt", "ground", "grass",
        "unpaved", "sand", "unknown" 
    ])
    surface_plot_base_y_offset_factor: float = 0.05 # 5% der Plot-Höhe über dem Max-Peak
    surface_plot_line_spacing_factor: float = 0.02 # 2% der Plot-Höhe als Abstand
    surface_plot_linewidth: float = 2.0
    surface_plot_alpha: float = 0.7

# ------------------------------------------------------------
#  Datenklasse Segment (unverändert)
# ------------------------------------------------------------
@dataclass
class Segment:
    peak_rank: int
    start_idx: int
    end_idx: int
    gain_m: float
    length_m: float
    direction: str # 'forward' or 'backward'

    @property
    def valid(self) -> bool:
        # IMPORTANT: Access threshold via the *instance* of Config passed around
        # Assuming the Config object is available in the scope where this is checked
        # This might need adjustment depending on how Config is passed.
        # For now, assuming a global or passed config object.
        # A better way would be to pass config to the Segment or check externally.
        # Let's assume it's checked externally for now, or Config needs to be global/passed.
        # Example if passed: def valid(self, config: Config) -> bool: ...
        # Hardcoding for now, needs refinement if Config isn't easily accessible here.
        return self.gain_m >= 30.0 # Fallback to hardcoded value

    def get_index_range(self) -> Set[int]:
        return set(range(self.start_idx, self.end_idx + 1))

# ------------------------------------------------------------
#  Helfer (angepasst für Config-Instanz)
# ------------------------------------------------------------
# smooth_elev (unverändert)
def smooth_elev(elev: np.ndarray, config: Config) -> np.ndarray:
    if len(elev) < config.smooth_window: return elev.copy()
    # Ensure window is odd and smaller than array length
    window = config.smooth_window if config.smooth_window % 2 != 0 else config.smooth_window + 1
    if window > len(elev):
        window = len(elev) if len(elev) % 2 != 0 else len(elev) - 1
        if window < 3: return elev.copy() # Need at least 3 points for poly order 2
    poly = config.smooth_poly
    # Ensure poly order is less than window size
    if poly >= window:
        poly = window - 1
        if poly < 1: poly = 1 # Minimum poly order is 1
    try:
        return savgol_filter(elev, window, poly)
    except ValueError as e:
        print(f"[Warnung] Fehler bei Savgol-Filter (window={window}, poly={poly}, len={len(elev)}): {e}. Ungeglättete Daten werden verwendet.")
        return elev.copy()

# ------------------------------------------------------------
#  Analyse‑Routinen (angepasst für Config-Instanz)
# ------------------------------------------------------------
# analyse_direction (unverändert)
def analyse_direction(
    elev: np.ndarray, dist: np.ndarray, peak_idx: int, direction: str,
    peak_rank: int, n: int, config: Config, excluded_indices: Optional[Set[int]] = None
) -> Tuple[List[Segment], List[Segment]]:
    """Analyzes segments in one direction from a peak."""
    if not (0 <= peak_idx < n): return [], []
    excluded_indices = excluded_indices or set()
    step = 1 if direction == "forward" else -1
    i = peak_idx + step

    mode = "falling" # Start assuming we are falling from the peak
    current_gain = 0.0
    segment_start_idx = -1 # Index where the current potential rising segment started

    all_found: List[Segment] = []
    first_valid: List[Segment] = []

    while 0 <= i < n:
        if i in excluded_indices:
            # If we hit an excluded index while rising, reset the segment
            if mode == "rising":
                mode = "falling"
                current_gain = 0.0
                segment_start_idx = -1
            i += step
            continue

        # Get previous index, ensure it's valid and not excluded
        prev_idx = i - step
        if not (0 <= prev_idx < n): break # Should not happen if loop condition is correct
        if prev_idx in excluded_indices:
            # If the previous point was excluded, we can't calculate diff, reset if rising
            if mode == "rising":
                 mode = "falling"
                 current_gain = 0.0
                 segment_start_idx = -1
            i += step
            continue

        # Calculate elevation difference
        diff = elev[i] - elev[prev_idx]

        # Ignore negligible height changes
        if abs(diff) < config.eps_height:
            i += step
            continue

        if mode == "falling":
            # If we start rising, mark the beginning of a potential segment
            if diff > 0:
                mode = "rising"
                segment_start_idx = prev_idx
                current_gain = diff
        else: # mode == "rising"
            # Continue accumulating gain if still rising
            if diff > 0:
                current_gain += diff
            # If we start falling, the rising segment ends
            else:
                segment_end_idx = prev_idx
                # Only record if a valid start was found
                if segment_start_idx != -1:
                    length_m = abs(dist[segment_end_idx] - dist[segment_start_idx])
                    # Ensure indices are ordered correctly for the Segment object
                    idx1, idx2 = min(segment_start_idx, segment_end_idx), max(segment_start_idx, segment_end_idx)
                    # Pass config.gain_threshold to check validity explicitly if needed
                    # For now, rely on the property check later
                    seg = Segment(peak_rank, idx1, idx2, current_gain, length_m, direction)
                    all_found.append(seg)
                    # Check validity using the threshold from config
                    if seg.gain_m >= config.gain_threshold and not first_valid:
                        first_valid.append(seg)
                        # break # Optional: Stop after finding the first valid segment
                # Reset for the next potential segment
                mode = "falling"
                current_gain = 0.0
                segment_start_idx = -1
        i += step

    # Handle case where a rising segment goes to the very end/start of the track
    if mode == "rising" and segment_start_idx != -1:
         segment_end_idx = i - step # The last valid index processed
         length_m = abs(dist[segment_end_idx] - dist[segment_start_idx])
         idx1, idx2 = min(segment_start_idx, segment_end_idx), max(segment_start_idx, segment_end_idx)
         seg = Segment(peak_rank, idx1, idx2, current_gain, length_m, direction)
         all_found.append(seg)
         if seg.gain_m >= config.gain_threshold and not first_valid:
             first_valid.append(seg)


    return all_found, first_valid

# analyze_single_peak (unverändert)
def analyze_single_peak(
    peak_idx: int, peak_rank: int, elev: np.ndarray, dist: np.ndarray,
    track_len_km: float, n: int, config: Config, excluded_indices: Optional[Set[int]] = None
) -> Tuple[List[Segment], Set[int]]:
    """Analyzes segments forward and backward from a single peak."""
    peak_dist_km = dist[peak_idx] / 1000.0
    peak_elev_m = elev[peak_idx]
    segments: List[Segment] = []
    valid_segment_indices: Set[int] = set()

    print(f"  Analysiere Peak {peak_rank} ({peak_elev_m:.1f} m @ {peak_dist_km:.2f} km):")

    # Check if peak is too close to the edges
    is_peak_near_start = peak_dist_km <= config.peak_edge_km
    is_peak_near_end = (track_len_km - peak_dist_km) <= config.peak_edge_km

    # --- Forward Analysis ---
    if is_peak_near_end:
        print(f"    -> P{peak_rank} am Ende - keine Vorwärtsanalyse.")
    else:
        all_fwd, valid_fwd = analyse_direction(elev, dist, peak_idx, "forward", peak_rank, n, config, excluded_indices)
        segments.extend(all_fwd)
        # Check validity explicitly using config
        valid_fwd_filtered = [s for s in valid_fwd if s.gain_m >= config.gain_threshold]
        if valid_fwd_filtered:
            s = valid_fwd_filtered[0]
            end_hint = " (-> Ende)" if s.end_idx == n - 1 else ""
            print(f"    -> OK P{peak_rank} Vorwärts: +{s.gain_m:.1f} m / {s.length_m:.0f} m{end_hint}")
            valid_segment_indices.update(s.get_index_range())
        else:
            print(f"    -> !! P{peak_rank} Vorwärts: Kein signif. Segment.")

    # --- Backward Analysis ---
    if is_peak_near_start:
        print(f"    <- P{peak_rank} am Start - keine Rückwärtsanalyse.")
    else:
        all_bwd, valid_bwd = analyse_direction(elev, dist, peak_idx, "backward", peak_rank, n, config, excluded_indices)
        segments.extend(all_bwd)
        # Check validity explicitly using config
        valid_bwd_filtered = [s for s in valid_bwd if s.gain_m >= config.gain_threshold]
        if valid_bwd_filtered:
            s = valid_bwd_filtered[0]
            start_hint = " (<- Start)" if s.start_idx == 0 else ""
            print(f"    <- OK P{peak_rank} Rückwärts: +{s.gain_m:.1f} m / {s.length_m:.0f} m{start_hint}")
            valid_segment_indices.update(s.get_index_range())
        else:
            print(f"    <- !! P{peak_rank} Rückwärts: Kein signif. Segment.")

    return segments, valid_segment_indices


# ------------------------------------------------------------
#  Statistik-Berechnung (angepasst für Config Instanz bei Pausen)
# ------------------------------------------------------------
def calculate_statistics(df: pd.DataFrame, config: Config) -> Dict[str, any]: # Verwende Any für flexible Typen
    """Calculates overall and time-based statistics. Returns None for unavailable stats."""
    stats = {}
    n_points = len(df)
    if n_points < 2: return {"Fehler": "Zu wenig Datenpunkte"}

    # --- Basic Stats ---
    stats["Gesamtdistanz (km)"] = df["Distanz (km)"].iloc[-1] if "Distanz (km)" in df.columns else None # Verwende None statt 0.0

    stats["Gesamtdistanz (km)"] = df["Distanz (km)"].iloc[-1] if "Distanz (km)" in df.columns else None
    has_elevation = 'Elevation (m)' in df.columns and df['Elevation (m)'].notna().any()
    if has_elevation:
        stats["Minimalhöhe (m)"] = df["Elevation (m)"].min(); stats["Maximalhöhe (m)"] = df["Elevation (m)"].max()
        stats["Gesamter Aufstieg (m)"] = df["Aufstieg (m)"].sum() if 'Aufstieg (m)' in df.columns else None
        elevation_diff = df['Elevation (m)'].diff().fillna(0); stats["Gesamter Abstieg (m)"] = abs(elevation_diff.clip(upper=0).sum())
    else:
        stats["Minimalhöhe (m)"] = None; stats["Maximalhöhe (m)"] = None; stats["Gesamter Aufstieg (m)"] = None; stats["Gesamter Abstieg (m)"] = None

    # --- Time Stats (Nur wenn Zeitdaten vorhanden) ---
    if 'Time' in df.columns and df['Time'].notna().any(): # Ebene 1 if
        df_time_col = pd.to_datetime(df['Time'], errors='coerce')

        if df_time_col.notna().any(): # Ebene 2 if
            valid_times_df = df_time_col.dropna()
            if len(valid_times_df) >= 2: # Ebene 3 if
                start_time = valid_times_df.iloc[0]
                end_time = valid_times_df.iloc[-1]
                total_duration_td = end_time - start_time
                stats["Gesamtdauer"] = str(total_duration_td).split('.')[0]

                pause_duration_s = 0.0
                df_temp_pause = df[['Time', 'Strecke Delta (km)']].copy()
                df_temp_pause['Time'] = pd.to_datetime(df_temp_pause['Time'], errors='coerce')
                df_temp_pause.dropna(subset=['Time'], inplace=True)

                if len(df_temp_pause) >=2: # Ebene 4 if
                    df_temp_pause['TimeDelta (s)'] = df_temp_pause['Time'].diff().dt.total_seconds().fillna(0)
                    df_temp_pause['DistDelta (m)'] = df_temp_pause['Strecke Delta (km)'] * 1000
                    for i in range(1, len(df_temp_pause)):
                        time_diff = df_temp_pause['TimeDelta (s)'].iloc[i]
                        dist_diff = df_temp_pause['DistDelta (m)'].iloc[i]
                        if time_diff >= config.pause_min_duration_s and dist_diff <= config.pause_max_distance_m:
                            pause_duration_s += time_diff

                    moving_duration_s = max(0, total_duration_td.total_seconds() - pause_duration_s)
                    stats["Pausenzeit"] = str(pd.to_timedelta(pause_duration_s, unit='s')).split('.')[0]
                    stats["Bewegungszeit"] = str(pd.to_timedelta(moving_duration_s, unit='s')).split('.')[0]

                    total_duration_h = total_duration_td.total_seconds() / 3600
                    moving_duration_h = pd.to_timedelta(moving_duration_s, unit='s').total_seconds() / 3600
                    dist_km_val = stats.get("Gesamtdistanz (km)")
                    dist_km = float(dist_km_val) if dist_km_val is not None else 0.0

                    stats["Ø Geschwindigkeit (km/h)"] = (dist_km / total_duration_h) if total_duration_h > 0 else None
                    stats["Ø Geschw. in Bewegung (km/h)"] = (dist_km / moving_duration_h) if moving_duration_h > 0 else None
                else: # Gehört zu Ebene 4 if
                    print("[Warnung] Nicht genug gültige Zeitpunkte für Pausenberechnung.")
                    stats["Pausenzeit"] = None; stats["Bewegungszeit"] = None
                    stats["Ø Geschwindigkeit (km/h)"] = None; stats["Ø Geschw. in Bewegung (km/h)"] = None
            else: # Gehört zu Ebene 3 if
                print("[Warnung] Nicht genug gültige Zeitpunkte für Gesamtdauer.")
                stats["Gesamtdauer"] = None; stats["Pausenzeit"] = None; stats["Bewegungszeit"] = None
                stats["Ø Geschwindigkeit (km/h)"] = None; stats["Ø Geschw. in Bewegung (km/h)"] = None
        else: # Gehört zu Ebene 2 if
            print("[Info] Keine validen Zeitdaten für Statistikberechnung nach Konvertierung gefunden.")
            stats["Gesamtdauer"] = None; stats["Pausenzeit"] = None; stats["Bewegungszeit"] = None
            stats["Ø Geschwindigkeit (km/h)"] = None; stats["Ø Geschw. in Bewegung (km/h)"] = None
    else: # Gehört zu Ebene 1 if
        print("[Info] Keine Zeitdaten-Spalte für Statistikberechnung gefunden.")
        stats["Gesamtdauer"] = None; stats["Pausenzeit"] = None; stats["Bewegungszeit"] = None
        stats["Ø Geschwindigkeit (km/h)"] = None; stats["Ø Geschw. in Bewegung (km/h)"] = None    # ---------------------------------------------------

    # Format Floats und entferne Nones
    stats_formatted = {}
    for key, value in stats.items():
        if value is not None:
            if isinstance(value, (float, np.float64)):
                stats_formatted[key] = f"{value:.2f}"
            else:
                stats_formatted[key] = value # Strings (wie formatierte Dauer) bleiben erhalten

    return stats_formatted
# ------------------------------------------------------------
#  Plot‑Funktionen (ERWEITERT für Orte)
# ------------------------------------------------------------
# _calculate_slope_colors (unverändert)
def _calculate_slope_colors(dist_m: np.ndarray, elev_m: np.ndarray, config: Config) -> Tuple[np.ndarray, ListedColormap, BoundaryNorm]:
    """Berechnet Steigungsprozente und weist Farben basierend auf Schwellen zu."""
    if len(dist_m) < 2: return np.array([]), ListedColormap([]), BoundaryNorm([], 0)

    d_elev = np.gradient(elev_m)
    d_dist = np.gradient(dist_m)

    slope_percent = np.zeros_like(d_dist)
    min_dist_step = 1e-1
    valid_dist_mask = d_dist > min_dist_step

    slope_percent[valid_dist_mask] = (d_elev[valid_dist_mask] / d_dist[valid_dist_mask]) * 100
    slope_percent = np.clip(slope_percent, config.slope_thresholds[0], config.slope_thresholds[-1])

    cmap = ListedColormap(config.slope_colors)
    norm = BoundaryNorm(config.slope_thresholds, cmap.N)
    slope_indices = np.digitize(slope_percent[:-1], config.slope_thresholds[1:], right=False)

    return slope_indices, cmap, norm

# _shade_segment (unverändert)
def _shade_segment(ax, dist_km: np.ndarray, elev_m: np.ndarray, seg: Segment, config: Config):
    """
    Zeichnet Hintergrundschattierungen und Labels für Segmente.
    JETZT: Zeichnet nichts mehr, da die Funktionalität entfernt wurde.
    Behalte die Funktion als Platzhalter oder entferne sie und ihre Aufrufe komplett.
    """
    is_valid = seg.gain_m >= config.gain_threshold

    # --- ENTFERNT ---
    # if is_valid:
    #     shade_color = config.color_fwd_shade if seg.direction == "forward" else config.color_bwd_shade
    #     shade_alpha = config.shade_alpha
    #     # text_color = config.color_fwd_valid_label if seg.direction == "forward" else config.color_bwd_valid_label # Nicht mehr benötigt
    # else: # Invalid segment
    #     shade_color = config.color_invalid
    #     shade_alpha = config.invalid_alpha
        # text_color = "#666666" # Nicht mehr benötigt

    # x0_km, x1_km = dist_km[seg.start_idx], dist_km[seg.end_idx]
    # segment_width_km = abs(x1_km - x0_km)

    # --- ENTFERNT: axvspan ---
    # if is_valid or seg.length_m >= config.min_length_draw_m:
    #      ax.axvspan(x0_km, x1_km, color=shade_color, alpha=shade_alpha, zorder=1, lw=0)

    # --- ENTFERNT: ax.text für Segment-Label ---
    # if is_valid and segment_width_km > 0.5:
    #     text_x_km = (x0_km + x1_km) / 2
    #     seg_indices = range(seg.start_idx, seg.end_idx + 1)
    #     if not list(seg_indices): return
    #     text_y_max_in_segment = np.max(elev_m[list(seg_indices)])
    #     y_offset = 5
    #     ax.text(text_x_km, text_y_max_in_segment + y_offset, f"P{seg.peak_rank}:{seg.gain_m:.0f}m",
    #             ha="center", va="bottom", fontsize=8,
    #             color=text_color, weight='bold',
    #             bbox=dict(boxstyle="round,pad=0.15", fc="white", ec="none", alpha=0.75),
    #             zorder=5)
    pass # Funktion tut jetzt nichts mehr oder kann ganz entfernt werden


# --- Nächsten Nachbarn finden (ERWEITERT: gibt Distanz zurück) ---
def find_nearest_track_point_kdtree(track_lat_lon: np.ndarray, place_lat: float, place_lon: float) -> Tuple[int, float]:
    """
    Finds the index and approximate distance (in meters) of the nearest track point using KDTree.
    Assumes track_lat_lon is an Nx2 array with [Latitude, Longitude].
    Returns (index, distance_meters) or (-1, -1.0) on error.
    """
    if track_lat_lon is None or track_lat_lon.shape[0] == 0:
        return -1, -1.0
    try:
        tree = KDTree(track_lat_lon)
        distance_deg, index = tree.query([place_lat, place_lon])

        # Konvertiere Distanz von Grad zu Metern (Annäherung!)
        # Genauere Methode: Geopy verwenden, nachdem der Index gefunden wurde.
        nearest_track_point = track_lat_lon[index]
        try:
            # Verwende geopy für genauere Distanzberechnung
            distance_m = geopy_distance((place_lat, place_lon), (nearest_track_point[0], nearest_track_point[1])).meters
        except ValueError:
             # Fallback auf Grad-Umrechnung bei geopy-Fehler
             print("[Warnung] Geopy-Distanzberechnung fehlgeschlagen, nutze Grad-Approximation.")
             distance_m = distance_deg * 111000 # Grobe Annäherung

        return index, distance_m
    except Exception as e:
        print(f"[Warnung] KDTree Fehler: {e}")
        return -1, -1.0


# --- plot_profile (ERWEITERT um dynamischen Orts-Offset) ---
def plot_profile(base_filename: str,
                 track_df: pd.DataFrame, # Dies ist plot_df_for_plot aus main
                 peak_indices: List[int],
                 all_segments: List[Segment],
                 config: Config,
                 output_plot_path: str,
                 places_coords_df: Optional[pd.DataFrame] = None,
                 water_pois_to_plot_df: Optional[pd.DataFrame] = None,
                 surface_data_for_plot: Optional[pd.DataFrame] = None):
    print(f"[Info] Erstelle Plot: {output_plot_path}")
    fig, ax = plt.subplots(figsize=(14, 7.5))

    dist_m = track_df['Distanz (km)'].values * 1000.0
    elev_m = track_df['Elevation (m)'].values
    dist_km = dist_m / 1000.0
    n_points = len(dist_m)

    if n_points < 2:
        print("[Warnung] Weniger als 2 Punkte für Plot vorhanden.")
        # ... (deine Logik zum Erstellen einer leeren Plot-Datei und return) ...
        plt.close(fig)
        try:
            output_dir = os.path.dirname(output_plot_path)
            if output_dir: os.makedirs(output_dir, exist_ok=True)
            open(output_plot_path, 'a').close()
            print(f"[Info] Leere Plot-Datei erstellt: {output_plot_path}")
        except Exception as e:
            print(f"[Warnung] Konnte leere Plot-Datei nicht erstellen: {e}")
        return

    # ==========================================================================
    # SCHRITT 1: HAUPT-HÖHENPROFIL (Slope Colors) ZEICHNEN
    # ==========================================================================
    print("[DEBUG] Zeichne Haupt-Höhenprofil mit Slope Colors...", file=sys.stderr)
    slope_indices, cmap, norm = _calculate_slope_colors(dist_m, elev_m, config)

    # Fallback, falls keine Slope-Indizes berechnet werden konnten oder zu wenig Punkte
    if len(slope_indices) == 0 or n_points < 2:
        ax.plot(dist_km, elev_m, color='grey', linewidth=config.slope_linewidth, zorder=2, label='Höhenprofil')
        print("[Warnung] Slope-Indizes nicht berechnet oder zu wenig Punkte, zeichne graues Profil.", file=sys.stderr)
    else:
        # Hauptpfad mit farbiger Linie
        points = np.array([dist_km, elev_m]).T.reshape(-1, 1, 2)
        segments_lc = np.concatenate([points[:-1], points[1:]], axis=1)

        lc = LineCollection(segments_lc, cmap=cmap, norm=norm, linewidth=config.slope_linewidth, zorder=2)
        # !!! HIER IST DIE WICHTIGE ERGÄNZUNG !!!
        lc.set_array(slope_indices) # Weise die Farbwerte den Segmenten zu
        # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

        ax.add_collection(lc)

    # Setze X-Limits basierend auf den Daten
    ax.set_xlim(dist_km.min() if n_points > 0 else 0, dist_km.max() if n_points > 0 else 1)
    
    # Initiale Y-Limits basierend auf reinen Höhendaten des Tracks
    data_ymin = elev_m.min() if n_points > 0 else 0
    data_ymax = elev_m.max() if n_points > 0 else 100
    plot_data_height_range = data_ymax - data_ymin
    if plot_data_height_range <= 0: plot_data_height_range = 100 # Fallback für flache Tracks

    # Definiere Puffer für Annotationen etc.
    top_buffer_for_annotations = plot_data_height_range * 0.15 
    if top_buffer_for_annotations < 50: top_buffer_for_annotations = 50
    
    # Setze die initialen Y-Limits, die das Profil und Platz für Annotationen umfassen
    current_plot_ymin = data_ymin - (plot_data_height_range * 0.05 if plot_data_height_range > 0 else 10)
    current_plot_ymax = data_ymax + top_buffer_for_annotations
    ax.set_ylim(current_plot_ymin, current_plot_ymax)
    print(f"[DEBUG] Initiale Y-Limits nach Profilzeichnung: ({current_plot_ymin:.1f}, {current_plot_ymax:.1f})", file=sys.stderr)
    # --- ENDE HAUPT-HÖHENPROFIL ZEICHNEN ---

    # ==========================================================================
    # SCHRITT 2: OBERFLÄCHEN-OVERLAY ZEICHNEN
    # ==========================================================================
    # Dieser Block kommt NACHDEM das Hauptprofil und seine Y-Achse initial gesetzt wurden.
    if config.surface_plot_enabled and surface_data_for_plot is not None and \
       not surface_data_for_plot.empty and \
       hasattr(config, 'surface_plot_dist_col') and config.surface_plot_dist_col:
        
        print("[Info] Zeichne Oberflächen-Overlay im Bereich 75-90%...", file=sys.stderr)
        
        # Y-Positionen basierend auf data_ymin und plot_data_height_range (bereits oben definiert)
        overlay_bottom_percent = 0.75 
        overlay_top_percent = 0.90   
        
        y_overlay_start_abs = data_ymin + (plot_data_height_range * overlay_bottom_percent)
        y_overlay_end_abs = data_ymin + (plot_data_height_range * overlay_top_percent)
        available_y_for_surfaces = y_overlay_end_abs - y_overlay_start_abs
        
        surfaces_to_draw = [s.lower() for s in config.surface_plot_order if s.lower() in config.surface_plot_colors]
        if "unknown" not in surfaces_to_draw and "unknown" in config.surface_plot_colors:
            surfaces_to_draw.append("unknown")
        # Sortiere nach der Reihenfolge in config.surface_plot_order
        surfaces_to_draw = sorted(list(set(surfaces_to_draw)), key=lambda x: config.surface_plot_order.index(x) if x in config.surface_plot_order else float('inf'))

        num_surface_lines = len(surfaces_to_draw)
        y_spacing_surface_overlay = 0 
        base_y_to_plot = y_overlay_start_abs

        if num_surface_lines == 0:
             print("[Warnung] Keine Oberflächen für Overlay definiert oder Farben fehlen.")
        elif num_surface_lines == 1: # Spezialfall für nur eine Linie
            y_spacing_surface_overlay = 0 # Kein Abstand nötig
            if surfaces_to_draw: # Nur wenn die Liste nicht leer ist
                 base_y_to_plot = (y_overlay_start_abs + y_overlay_end_abs) / 2 # Zentriere die einzelne Linie
        else: # Mehr als eine Linie
            y_spacing_surface_overlay = available_y_for_surfaces / (num_surface_lines - 1)
            min_visual_spacing_lines = config.surface_plot_linewidth * 1.2 # Faktor für Mindestabstand
            if y_spacing_surface_overlay < min_visual_spacing_lines:
                print(f"[Warnung] Berechneter Y-Abstand für Oberflächen ({y_spacing_surface_overlay:.2f}) ist sehr klein (min: {min_visual_spacing_lines:.2f}). Linien könnten überlappen.")
                # Optional: y_spacing_surface_overlay = min_visual_spacing_lines # Erzwinge Mindestabstand

        surface_y_positions = {}
        if num_surface_lines > 0 and surfaces_to_draw:
            for i, surface_key in enumerate(surfaces_to_draw):
                y_val_for_line = base_y_to_plot if num_surface_lines == 1 else (base_y_to_plot + (i * y_spacing_surface_overlay))
                surface_y_positions[surface_key] = y_val_for_line
        
        print(f"[DEBUG] Berechnete Y-Positionen für Oberflächen: {surface_y_positions}", file=sys.stderr)

        dist_col_to_use = config.surface_plot_dist_col
        if dist_col_to_use and dist_col_to_use in surface_data_for_plot.columns:
            surface_data_for_plot['Surface_processed'] = surface_data_for_plot['Surface'].astype(str).str.lower()
            surface_data_for_plot['Surface_Block_Plot'] = (surface_data_for_plot['Surface_processed'] != surface_data_for_plot['Surface_processed'].shift()).cumsum()
            
            for _, segment in surface_data_for_plot.groupby('Surface_Block_Plot'):
                if segment.empty: continue
                surface_name = segment['Surface_processed'].iloc[0]
                start_dist_km = segment[dist_col_to_use].iloc[0]
                end_dist_km = segment[dist_col_to_use].iloc[-1]
                if pd.isna(start_dist_km) or pd.isna(end_dist_km) or start_dist_km >= end_dist_km: continue
                
                y_pos = surface_y_positions.get(surface_name)
                if y_pos is None: 
                    print(f"[Warnung] Keine Y-Position für Oberfläche '{surface_name}', überspringe Segment.", file=sys.stderr)
                    continue

                color = config.surface_plot_colors.get(surface_name, config.surface_plot_colors.get("default", "#888888"))
                ax.plot([start_dist_km, end_dist_km], [y_pos, y_pos],
                        color=color, linewidth=config.surface_plot_linewidth,
                        alpha=config.surface_plot_alpha, zorder=1.8) 
        else:
            print(f"[Warnung] Distanzspalte '{config.surface_plot_dist_col}' für Oberflächen-Overlay nicht in surface_data_for_plot gefunden.", file=sys.stderr)
        
        # Y-Achsenlimits anpassen, um die Oberflächenlinien und das Profil sicher einzuschließen
        _current_ymin_after_profile, _current_ymax_after_profile = ax.get_ylim()
        max_req_y_for_surfaces = _current_ymax_after_profile 
        if surface_y_positions:
            plotted_surface_y_values = [y_val for y_val in surface_y_positions.values() if pd.notna(y_val)]
            if plotted_surface_y_values:
                max_surface_line_y_val = max(plotted_surface_y_values)
                # Füge einen kleinen Puffer über der höchsten Oberflächenlinie hinzu
                puffer_above_surfaces = y_spacing_surface_overlay * 0.5 if y_spacing_surface_overlay > 0 and num_surface_lines > 1 else 10
                max_req_y_for_surfaces = max_surface_line_y_val + puffer_above_surfaces
        
        # Das neue obere Limit ist das Maximum aus dem bisherigen oberen Limit (das Peaks etc. berücksichtigt)
        # und dem, was für die Oberflächenlinien benötigt wird.
        ax.set_ylim(_current_ymin_after_profile, max(_current_ymax_after_profile, max_req_y_for_surfaces))
        print(f"[Info] Y-Achse nach Oberflächen-Overlay ggf. angepasst auf: ({ax.get_ylim()[0]:.1f}, {ax.get_ylim()[1]:.1f})", file=sys.stderr)
    # --- ENDE OBERFLÄCHEN-OVERLAY ---

    # --- SCHRITT 3: PEAKS MARKIEREN ---
    # (Dein korrigierter Code zum Markieren der Peaks)
    peak_colors = config.peak_highlight_colors 
    peak_handles = []
    peak_labels_text = []
    for i, current_peak_idx in enumerate(peak_indices): 
        if i >= len(peak_colors): color = "#7f7f7f" 
        else: color = peak_colors[i]
        peak_x_km = dist_km[current_peak_idx]
        peak_y_m = elev_m[current_peak_idx]
        label = f"Peak {i+1}"
        peak_labels_text.append(label)
        handle = plt.Line2D([0], [0], color=color, linestyle='--', linewidth=1.5, label=label)
        peak_handles.append(handle)
        ax.axvline(peak_x_km, color=color, linestyle="--", linewidth=1.5, zorder=3, alpha=0.8)
        ax.plot(peak_x_km, peak_y_m, 'o', color=color, markersize=7, zorder=4, mec='black', mew=0.5)
        ax.text(peak_x_km + 0.15 * (ax.get_xlim()[1] - ax.get_xlim()[0])/100 , 
                peak_y_m, f"{peak_y_m:.0f} m", color='black', fontsize=8, va='center', ha='left',
                bbox=dict(boxstyle="round,pad=0.15", fc=color, ec="black", lw=0.5, alpha=0.85), zorder=6)
                
    # 4. Shade Segments
    for seg in all_segments:
        is_valid = seg.gain_m >= config.gain_threshold
        _shade_segment(ax, dist_km, elev_m, seg, config) # Übergibt jetzt valides Segment


    # ***** 5. Orte annotieren (mit dynamischem Offset) *****
    place_annotations = [] # Liste zum Speichern der Annotationsdetails
    plotted_place_names = set() # Um doppelte Labels zu vermeiden, falls Orte nah beieinander liegen
    if places_coords_df is not None and not places_coords_df.empty:
        print("[Info] Füge Ortsmarker zum Plot hinzu...")
        track_coords_latlon = track_df[['Latitude', 'Longitude']].values
        if track_coords_latlon.shape[0] > 0:
            # Bereite Bins und Offsets vor
            dist_bins = np.array(config.place_offset_dist_bins_m)
            y_offsets = np.array(config.place_offset_y_additions)
            if len(y_offsets) != len(dist_bins) + 1:
                 print("[Warnung] Länge von place_offset_y_additions passt nicht zu place_offset_dist_bins_m! Verwende Basis-Offset.")
                 use_dynamic_offset = False
            else:
                 use_dynamic_offset = True

            for _, place_row in places_coords_df.iterrows():
                place_name = place_row['Ort']
                place_lat = place_row.get('Latitude_Center')
                place_lon = place_row.get('Longitude_Center')

                if pd.notna(place_lat) and pd.notna(place_lon):
                    nearest_idx, distance_m = find_nearest_track_point_kdtree(track_coords_latlon, place_lat, place_lon) # Erhalte auch Distanz

                    if nearest_idx != -1:
                        track_point = track_df.iloc[nearest_idx]
                        plot_dist_km = track_point['Distanz (km)']
                        plot_elev_m = track_point['Elevation (m)']

                        # Berechne zusätzlichen Y-Offset basierend auf Distanz-Binning
                        additional_offset_y = 0
                        if use_dynamic_offset:
                            # Finde den Index des Bins, in den die Distanz fällt
                            # np.digitize gibt Index des Bins zurück (beginnend bei 1)
                            # Indices sind 0 (<=bin[0]), 1 (bin[0]<..<bin[1]), ..., N (>=bin[N-1])
                            bin_index = np.digitize(distance_m, dist_bins)
                            additional_offset_y = y_offsets[bin_index]

                        total_y_offset = config.place_text_offset_y + additional_offset_y

                        # Speichere für späteres Plotten
                        place_annotations.append({
                            'name': place_name,
                            'x': plot_dist_km,
                            'y': plot_elev_m,
                            'y_offset': total_y_offset,
                            'distance_m': distance_m # Für Debugging oder spätere Verwendung
                        })
                    # ... (Warnung, wenn Punkt nicht gefunden) ...
                # ... (Warnung bei fehlenden Koordinaten) ...

            # Zeichne Marker und Texte für Orte
            # Sortiere Annotationen nach X-Position, um Überlappung besser handhaben zu können (optional)
            place_annotations.sort(key=lambda p: p['x'])
            last_label_x_end = -np.inf # Um Überlappung von Textboxen zu prüfen
            label_height = 15 # Geschätzte Höhe einer Textbox in Plot-Koordinaten

            for anno in place_annotations:
                 # Marker zeichnen
                 ax.plot(anno['x'], anno['y'],
                        marker=config.place_marker_style, color=config.place_marker_color,
                        markersize=config.place_marker_size, linestyle='None', zorder=5)

                 # Text zeichnen (mit Überlappungsprüfung - einfach)
                 # Wenn das neue Label horizontal mit dem alten überlappt, erhöhe Y weiter
                 current_label_y = anno['y'] + anno['y_offset']
                 # Einfache horizontale Überlappungsprüfung (könnte verfeinert werden)
                 # if anno['x'] < last_label_x_end:
                 #      current_label_y += label_height # Schiebe es weiter hoch

                 ax.text(anno['x'], current_label_y, anno['name'],
                        color=config.place_text_color, fontsize=config.place_text_size,
                        ha='center', va='bottom',
                        bbox=dict(boxstyle="round,pad=0.15", fc="white", ec=config.place_marker_color, lw=0.5, alpha=config.place_text_bg_alpha),
                        zorder=6)
                 # Aktualisiere die Position des letzten Labels (vereinfacht)
                 # TODO: Präzisere BBox-Kollisionserkennung wäre komplexer
                 # last_label_x_end = anno['x'] + (len(anno['name']) * 0.1) # Grobe Schätzung der Textbreite

        # ... (Warnung KDTree nicht verfügbar) ...

    # ***** NEU: 5a Wasserstellen annotieren *****
    water_poi_annotations = []
    if water_pois_to_plot_df is not None and not water_pois_to_plot_df.empty:
        print("[Info] Füge Wasserstellen-Marker zum Plot hinzu...")
        track_coords_latlon = track_df[['Latitude', 'Longitude']].values # Wiederverwenden oder neu holen
        
        if track_coords_latlon.shape[0] > 0:
            for _, poi_row in water_pois_to_plot_df.iterrows():
                poi_name = poi_row.get('Name', 'Wasser') # Fallback-Name
                poi_lat = poi_row.get('Latitude')
                poi_lon = poi_row.get('Longitude')

                if pd.notna(poi_lat) and pd.notna(poi_lon):
                    nearest_idx, distance_to_track_m = find_nearest_track_point_kdtree(
                        track_coords_latlon, poi_lat, poi_lon
                    )

                    if nearest_idx != -1:
                        track_point = track_df.iloc[nearest_idx]
                        plot_dist_km = track_point['Distanz (km)']
                        # Y-Position für Wasserstellen: kann auf Track-Höhe oder fest sein
                        # plot_elev_m_poi = track_point['Elevation (m)'] # Auf Track-Höhe
                        
                        # Für eine konsistente Darstellung etwas unterhalb der Hauptlinie:
                        min_elevation_on_plot = ax.get_ylim()[0]
                        plot_elev_m_poi_fixed = min_elevation_on_plot + 10 # Knapp über dem unteren Rand (anpassen)
                        
                        water_poi_annotations.append({
                            'name': poi_name,
                            'x': plot_dist_km,
                            'y_marker': plot_elev_m_poi_fixed, # Y für den Marker
                            # 'y_text': plot_elev_m_poi_fixed - 5, # Y für Text (optional, falls benötigt)
                            'distance_to_track_m': distance_to_track_m
                        })
                    else:
                        print(f"[Warnung Plot] Nächster Trackpunkt für Wasserstelle '{poi_name}' nicht gefunden.")
                else:
                    print(f"[Warnung Plot] Fehlende Koordinaten für Wasserstelle '{poi_name}'.")
        else:
            print("[Warnung Plot] Keine Track-Koordinaten für KDTree vorhanden (Wasserstellen).")

    # NEU: Wasserstellen plotten
    if water_poi_annotations:
        water_marker_color = 'deepskyblue'
        water_marker_style = 'o' # runder Marker
        water_marker_size = 3
        
        for anno in water_poi_annotations:
            ax.plot(anno['x'], anno['y_marker'],
                    marker=water_marker_style, color=water_marker_color,
                    markersize=water_marker_size, linestyle='None', zorder=5,
                    markeredgecolor=None, mew=0.5)
            # Optional: Text für Wasserstellen (kann schnell unübersichtlich werden)
            # ax.text(anno['x'], anno['y_marker'] - 8, "💧", # oder anno['name']
            #         color=water_marker_color, fontsize=7,
            #         ha='center', va='top', zorder=6)

    # ... (Achsen, Ticks, Titel, Grid, Legende wie vorher, aber Legende anpassen) ...
    # 6. FINALE ACHSEN-SETUP, TITEL, GRID (wird NACH allen Zeichenoperationen aufgerufen)
    ax.set_xlabel("Distanz (km)")
    ax.set_ylabel("Höhe (m)")
    ax.set_title(f"Analyse (Steigung, Peaks & Orte) – {base_filename}", pad=15) # Titel angepasst
    ax.grid(True, which='major', linestyle='-', linewidth='0.4', color='lightgray', zorder=0)
    ax.grid(True, which='minor', linestyle=':', linewidth='0.3', color='#ebebeb', zorder=0)
    ax.xaxis.set_major_locator(ticker.MultipleLocator(config.plot_x_tick_major))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(config.plot_x_tick_minor))
    ax.yaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='both', which='major', labelsize=9)

    # 7. Legende
    # ---------- HAUPT LEGENDE ----------
    slope_handles = [Patch(color=color, label=label) for color, label in zip(config.slope_colors, config.slope_labels)]

    place_handle = []
    if place_annotations:
         place_handle = [plt.Line2D([0], [0], marker=config.place_marker_style, color=config.place_marker_color, label='Ort', linestyle='None', markersize=config.place_marker_size)]

    water_handle = []
    if water_poi_annotations:
        water_handle = [plt.Line2D([0], [0], marker=water_marker_style, color=water_marker_color, label='Wasserstelle', linestyle='None', markersize=water_marker_size)]

    all_handles = peak_handles + place_handle + water_handle + slope_handles

    # Labels für die Hauptlegende (Peak-Labels werden direkt aus peak_labels_text genommen)
    main_legend_labels = list(peak_labels_text) # Kopie erstellen
    if place_annotations: main_legend_labels.append('Ort')
    if water_poi_annotations: main_legend_labels.append('Wasserstelle')
    main_legend_labels.extend(config.slope_labels) # Hier die Slope-Labels hinzufügen

    num_legend_items = len(all_handles)
    ncol_main = 6 if num_legend_items > 15 else 5 if num_legend_items > 10 else 4

    # Erstelle die Hauptlegende
    main_legend = fig.legend(handles=all_handles, labels=main_legend_labels, # Verwende die expliziten Labels
                             loc='lower center', bbox_to_anchor=(0.5, 0.01),
                             ncol=ncol_main, fontsize=8, title="Legende", title_fontsize=9)
    # Füge die Hauptlegende zur Figure hinzu, damit sie nicht überschrieben wird
    fig.add_artist(main_legend)

    # ---------- OBERFLÄCHEN LEGENDE ----------
    if config.surface_plot_enabled and surface_data_for_plot is not None and not surface_data_for_plot.empty:
        surface_legend_handles = []
        surface_legend_labels_list = []

        ordered_surfaces_for_legend = [s for s in config.surface_plot_order if s in config.surface_plot_colors]
        if "unknown" not in ordered_surfaces_for_legend and "unknown" in config.surface_plot_colors:
            ordered_surfaces_for_legend.append("unknown")

        for surface_name in ordered_surfaces_for_legend:
            color = config.surface_plot_colors.get(surface_name, config.surface_plot_colors.get("default"))
            handle = plt.Line2D([0], [0], color=color, lw=config.surface_plot_linewidth,
                                alpha=config.surface_plot_alpha)
            surface_legend_handles.append(handle)
            surface_legend_labels_list.append(surface_name.capitalize())

        if surface_legend_handles:
            # Positioniere die Oberflächenlegende UNTEN RECHTS und verkleinere sie
            surface_legend = ax.legend(handles=surface_legend_handles, labels=surface_legend_labels_list,
                                       loc='lower right',  # Position unten rechts
                                       title="Oberflächen",
                                       fontsize=6,         # Kleinere Schriftgröße für Items
                                       title_fontsize=7,   # Kleinere Schriftgröße für den Titel
                                       ncol=1,
                                       labelspacing=0.4,   # Reduziert den vertikalen Abstand zwischen Items
                                       handletextpad=0.5,  # Reduziert Abstand zwischen Handle und Text
                                       borderpad=0.4,      # Reduziert den Innenabstand des Legendenrahmens
                                       handlelength=1.5)   # Kürzere Länge der Farb-Handles
            surface_legend.get_frame().set_alpha(0.7)
            # surface_legend.get_frame().set_edgecolor('gray') # Optional: Heller Rahmen

    # Anpassung des rect für tight_layout, um sicherzustellen, dass beide Legenden passen
    # Der Wert für 'bottom' (zweiter Wert in rect) muss ggf. erhöht werden,
    # um Platz für die untere Hauptlegende zu schaffen.
    # Der Wert für 'top' (letzter Wert) bleibt meist gleich, es sei denn, die Oberflächenlegende
    # oben würde Platz beanspruchen, was hier nicht der Fall ist.
    fig.tight_layout(rect=[0, 0.10, 1, 0.96]) # Evtl. 0.08 oder 0.12 für bottom anpassen

    # 8. Save plot
    # ... (Speichern wie vorher) ...
    try:
        output_dir = os.path.dirname(output_plot_path)
        if output_dir: os.makedirs(output_dir, exist_ok=True)
        fig.savefig(output_plot_path, dpi=config.plot_dpi, bbox_inches='tight')
        print(f"  -> Plot gespeichert: '{output_plot_path}'")
    except Exception as e:
        print(f"  -> Fehler beim Speichern des Plots '{output_plot_path}': {e}")
    finally:
        plt.close(fig)


# ... (main Funktion muss angepasst werden, um die Config zu nutzen) ...
def main(args, config: Config):
    """Hauptfunktion: Verarbeitet eine CSV-Datei, erstellt Plot und Daten-CSVs."""
    print("Starte Peak/Profil Analyse V5 (mit dynamischem Orts-Offset)...")
    MAX_PEAKS_TO_ANALYZE = 4 # NEU: Definiere, wie viele Peaks maximal analysiert werden sollen

    # --- Lade Konfiguration aus Argumenten und Defaults ---
    config = Config(
        smooth_window=args.smooth_window, smooth_poly=args.smooth_poly,
        gain_threshold=args.gain_threshold, eps_height=args.eps_height,
        min_peak_prominence_m=args.prominence, peak_edge_km=args.peak_edge_km,
        plot_dpi=args.plot_dpi, plot_x_tick_major=args.plot_x_tick_major,
        plot_x_tick_minor=args.plot_x_tick_minor,
        pause_min_duration_s=args.pause_min_duration,
        pause_max_distance_m=args.pause_max_distance
        # Die neuen Offset-Parameter werden aktuell aus den Defaults der Klasse genommen.
        # Sie könnten auch über argparse / config.yaml konfigurierbar gemacht werden.
    )

    # --- Lade Eingabe-CSV (Track) ---
    # ... (Laden und Prüfen von track_df wie vorher) ...
    input_csv_path = args.input_csv
    base_filename = os.path.splitext(os.path.basename(input_csv_path))[0].replace("_track_data_full","")
    print(f"Verarbeite: {input_csv_path}")
    try: track_df = pd.read_csv(input_csv_path, parse_dates=['Time'], encoding='utf-8')
    except FileNotFoundError: print(f" Fehler: Eingabe-CSV nicht gefunden: {input_csv_path}"); sys.exit(1)
    except Exception as e: print(f" Fehler beim Lesen der CSV '{input_csv_path}': {e}"); sys.exit(1)
    required_cols = ['Distanz (km)', 'Elevation (m)', 'Time', 'Aufstieg (m)', 'Strecke Delta (km)', 'Latitude', 'Longitude']
    if not all(col in track_df.columns for col in required_cols): print(f" Fehler: Fehlende Spalten in {input_csv_path}. Benötigt: {required_cols}"); sys.exit(1)
    n_points = len(track_df)
    if n_points < max(20, config.smooth_window): # ... (handle too few points) ...
        print(f" Warnung: Zu wenig Punkte ({n_points})..."); open(args.output_plot, 'a').close(); open(args.output_peak_csv, 'a').close(); open(args.output_stats_csv, 'a').close(); print("[OK] Leere Ausgabedateien."); sys.exit(0)

    # --- Lade OPTIONALE Ortsdaten ---
    places_coords_df = None
    if args.places_coords_csv and os.path.exists(args.places_coords_csv):
         try:
             places_coords_df = pd.read_csv(args.places_coords_csv)
             if not all(c in places_coords_df.columns for c in ['Ort', 'Latitude_Center', 'Longitude_Center']):
                  print(f"[Warnung] Orts-CSV '{args.places_coords_csv}' fehlen Spalten. Ignoriere."); places_coords_df = None
             elif places_coords_df.empty: print(f"[Info] Orts-CSV '{args.places_coords_csv}' ist leer."); places_coords_df = None
             else: print(f"[Info] Ortsdaten für Annotation geladen: {args.places_coords_csv}")
         except Exception as e: print(f"[Warnung] Fehler beim Laden der Orts-CSV '{args.places_coords_csv}': {e}. Ignoriere."); places_coords_df = None
    else: print("[Info] Keine Ortsdaten-CSV für Annotation angegeben oder gefunden.")

    # --- Lade OPTIONALE POI-Daten für Wasserstellen ---
    water_pois_df = None
    if args.relevant_pois_csv and os.path.exists(args.relevant_pois_csv): # NEUES Argument
        try:
            all_relevant_pois_df = pd.read_csv(args.relevant_pois_csv)
            # Filtere nur 'drinking_water' POIs
            water_pois_df = all_relevant_pois_df[all_relevant_pois_df['Typ'].str.lower() == 'drinking_water'].copy()
            
            if not all(c in water_pois_df.columns for c in ['Name', 'Latitude', 'Longitude']): # Benötigte Spalten
                 print(f"[Warnung] Wasserstellen-relevante POI-CSV '{args.relevant_pois_csv}' fehlen Spalten 'Name', 'Latitude', 'Longitude'. Ignoriere Wasserstellen.")
                 water_pois_df = None
            elif water_pois_df.empty:
                print(f"[Info] Keine 'drinking_water' POIs in '{args.relevant_pois_csv}' gefunden.")
                water_pois_df = None
            else:
                print(f"[Info] Wasserstellen-POIs für Annotation geladen: {len(water_pois_df)} Stück.")
        except Exception as e:
            print(f"[Warnung] Fehler beim Laden der relevanten POI-CSV '{args.relevant_pois_csv}': {e}. Ignoriere Wasserstellen.")
            water_pois_df = None
    else:
        print("[Info] Keine relevante POI-CSV für Wasserstellen angegeben oder gefunden.")

    # --- Lade OPTIONALE Oberflächendaten (aus 4b) ---
    surface_data_df = None
    if args.surface_data_csv and os.path.exists(args.surface_data_csv):
        try:
            surface_data_df = pd.read_csv(args.surface_data_csv)
            # Erforderliche Spalten für das Overlay: Distanz und Oberfläche
            # Der Distanzspaltenname kommt aus der config, die in 4b verwendet wurde.
            # Wir nehmen an, es ist 'Distanz (km)', wie im plot_df_for_plot, oder der Name,
            # der auch in der 4b-Datei als Referenzdistanzspalte verwendet wurde.
            # In deinem 4b-Output heißt sie 'Distanz (km)' oder 'Distanz_km_orig_track'
            # Für Konsistenz wäre es gut, wenn 4b immer einen festen Namen ausgibt, z.B. 'Distanz_km_Track'
            
            # Finde die korrekte Distanzspalte im surface_data_df
            # (Diese Logik ist wichtig, da der Name variieren kann)
            dist_col_surface = None
            if 'Distanz (km)' in surface_data_df.columns: # Priorität 1
                dist_col_surface = 'Distanz (km)'
            elif 'Distanz_km_orig_track' in surface_data_df.columns: # Priorität 2 (aus 4b)
                 dist_col_surface = 'Distanz_km_orig_track'
            # Füge hier weitere Kandidaten hinzu, falls nötig

            if not (dist_col_surface and 'Surface' in surface_data_df.columns):
                print(f"[Warnung] Oberflächendaten-CSV '{args.surface_data_csv}' fehlen Spalten '{dist_col_surface or 'Distanz'}' oder 'Surface'. Ignoriere für Plot-Overlay.")
                surface_data_df = None
            elif surface_data_df.empty:
                print(f"[Info] Oberflächendaten-CSV '{args.surface_data_csv}' ist leer.")
                surface_data_df = None
            else:
                # Konvertiere Distanz zu numerisch und sortiere für korrekte Segmentbildung
                surface_data_df[dist_col_surface] = pd.to_numeric(surface_data_df[dist_col_surface], errors='coerce')
                surface_data_df.dropna(subset=[dist_col_surface, 'Surface'], inplace=True)
                if 'original_index' in surface_data_df.columns: # Beste Sortierung
                    surface_data_df.sort_values(by='original_index', inplace=True)
                else:
                    surface_data_df.sort_values(by=dist_col_surface, inplace=True)
                surface_data_df.reset_index(drop=True, inplace=True)
                # Speichere den verwendeten Distanzspaltennamen für die Plot-Funktion
                config.surface_plot_dist_col = dist_col_surface 
                print(f"[Info] Oberflächendaten für Plot-Overlay geladen ({len(surface_data_df)} Einträge, Distanzspalte: '{dist_col_surface}').")
        except Exception as e:
            print(f"[Warnung] Fehler beim Laden der Oberflächendaten-CSV '{args.surface_data_csv}': {e}. Ignoriere.")
            surface_data_df = None
    else:
        print("[Info] Keine Oberflächendaten-CSV für Plot-Overlay angegeben oder gefunden.")
        config.surface_plot_dist_col = None # Sicherstellen, dass das Attribut existiert



    # --- 2. Glätte Höhenprofil ---
    track_df['Elevation_smooth (m)'] = smooth_elev(track_df['Elevation (m)'].values, config)
    elev_smooth = track_df['Elevation_smooth (m)'].values
    dist_m = track_df['Distanz (km)'].values * 1000.0
    track_len_km = dist_m[-1] / 1000.0

    # --- 3. Finde Peaks ---
    # ... (Peak-Findung wie vorher) ...
    peak_indices, properties = find_peaks(elev_smooth, prominence=config.min_peak_prominence_m)
    peaks_to_analyze_indices = []
    if len(peak_indices) > 0:
        peak_heights = elev_smooth[peak_indices]
        sorted_peak_order = np.argsort(peak_heights)[::-1] # Sortiert nach Höhe absteigend
        sorted_peak_indices = peak_indices[sorted_peak_order]
        peaks_to_analyze_indices = sorted_peak_indices[:MAX_PEAKS_TO_ANALYZE] # Nimm die Top N Peaks
        print(f"  -> {len(peak_indices)} Peaks gefunden. Analysiere Top {len(peaks_to_analyze_indices)}:")
    else:
        print(f"  -> Keine signifikanten Peaks gefunden.")

    # --- 4. Analysiere Segmente ---
    # ... (Segment-Analyse wie vorher) ...
    all_segments_combined: List[Segment] = []; 
    peak_data_for_csv: List[Dict] = []; 
    
    for i, p_idx in enumerate(peaks_to_analyze_indices):
        peak_rank = i + 1
        print(f"  -> Analysiere Peak {peak_rank} (Index {p_idx})...")
        # Für eine einfachere Logik hier: keine exkludierten Indizes zwischen Peaks
        # Wenn du das willst, müsstest du valid_indices vom vorherigen Peak an den nächsten übergeben.
        segments_p, valid_indices_p = analyze_single_peak(
            p_idx, peak_rank, elev_smooth, dist_m, track_len_km, n_points, config, None # excluded_indices_for_next_peak
        )
        all_segments_combined.extend(segments_p)
        # excluded_indices_for_next_peak.update(valid_indices_p) # Wenn Überlappung vermieden werden soll
        peak_data_for_csv.append({
            "item_type": "Peak",
            "peak_rank": peak_rank,
            "peak_dist_km": dist_m[p_idx] / 1000.0,
            "peak_elev_m": elev_smooth[p_idx]
        })

    # --- 5. Berechne Gesamtstatistiken ---
    # ... (Statistik-Berechnung und Speichern wie vorher) ...
    print("[Info] Berechne Gesamtstatistiken...")
    stats_dict = calculate_statistics(track_df.copy(), config)
    stats_df = pd.DataFrame(list(stats_dict.items()), columns=["Statistik", "Wert"])
    try: output_dir = os.path.dirname(args.output_stats_csv); os.makedirs(output_dir, exist_ok=True); stats_df.to_csv(args.output_stats_csv, index=False, encoding='utf-8'); print(f"  -> Statistiken gespeichert: {args.output_stats_csv}")
    except Exception as e: print(f" Fehler beim Speichern der Statistiken '{args.output_stats_csv}': {e}")

    # --- 6. Bereite Peak/Segment Daten für CSV vor ---
    # ... (Peak/Segment-Daten speichern wie vorher) ...
    segment_data_for_csv: List[Dict] = []
    for seg in all_segments_combined:
        # Check validity using config threshold
        if seg.gain_m >= config.gain_threshold:
            # --- KORREKTE EINRÜCKUNG HIER ---
            notes = []
            # Check for start/end hints
            if seg.direction == "backward" and seg.start_idx == 0:
                notes.append("Starts@TrackBegin")
            if seg.direction == "forward" and seg.end_idx == n_points - 1: # n_points muss hier bekannt sein
                notes.append("Ends@TrackEnd")

            # Diese Zeile muss auf der gleichen Ebene wie notes=[] stehen
            segment_data_for_csv.append({
                "item_type": "Valid Segment",
                "peak_rank": seg.peak_rank,
                "segment_direction": seg.direction,
                "segment_start_km": dist_m[seg.start_idx] / 1000.0,
                "segment_end_km": dist_m[seg.end_idx] / 1000.0,
                "segment_length_m": seg.length_m,
                "segment_gain_m": seg.gain_m,
                "notes": "; ".join(notes)
            })
            # --- ENDE DES IF-BLOCKS ---

    # Nach der for-Schleife
    combined_data = peak_data_for_csv + segment_data_for_csv
    peak_segment_df = pd.DataFrame(combined_data)
    csv_cols = ["item_type", "peak_rank", "peak_dist_km", "peak_elev_m","segment_direction", "segment_start_km", "segment_end_km","segment_length_m", "segment_gain_m", "notes"]; peak_segment_df = peak_segment_df.reindex(columns=csv_cols) # Besser als manuelles hinzufügen
    try: output_dir = os.path.dirname(args.output_peak_csv); os.makedirs(output_dir, exist_ok=True); peak_segment_df.to_csv(args.output_peak_csv, index=False, encoding='utf-8', float_format='%.3f'); print(f"  -> Peak/Segment Daten gespeichert: {args.output_peak_csv}")
    except Exception as e: print(f" Fehler beim Speichern der Peak/Segment Daten '{args.output_peak_csv}': {e}")

    # --- 7. Erstelle Plot ---
    # Verwende den Original-Track df für Lat/Lon, aber mit geglätteter Höhe für die Y-Achse des Plots
    plot_df_for_plot = track_df[['Distanz (km)', 'Elevation_smooth (m)', 'Latitude', 'Longitude']].rename(columns={'Elevation_smooth (m)':'Elevation (m)'})
    plot_profile(base_filename, plot_df_for_plot,
                 list(peaks_to_analyze_indices),
                 all_segments_combined,
                 config,
                 args.output_plot,
                 places_coords_df,
                 water_pois_df,
                 surface_data_df)

    print(f" Analyse abgeschlossen für: {base_filename}")

# ------------------------------------------------------------
#  Command Line Interface (ERWEITERT für optionalen Orts-Input)
# ------------------------------------------------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Analyze GPX track data, find peaks, calculate stats, generate plots, and optionally annotate with places, water sources.")
    parser.add_argument("--input-csv", required=True, help="Path to the input track data CSV file (from step 2).")
    parser.add_argument("--output-plot", required=True, help="Path to save the output plot PNG file.")
    parser.add_argument("--output-peak-csv", required=True, help="Path to save the peak and segment data CSV file.")
    parser.add_argument("--output-stats-csv", required=True, help="Path to save the overall statistics CSV file.")
    parser.add_argument("--places-coords-csv", help="Optional path to the CSV file with places and coordinates (output of step 8b).") # Optionaler Input
    parser.add_argument("--relevant-pois-csv", help="Optional path to the CSV file with relevant POIs (e.g., for water sources).")     
    parser.add_argument("--surface-data-csv", help="Optional: Path to CSV with surface data (output of 4b).")    
    # Config arguments
    parser.add_argument("--smooth-window", type=int, default=11); parser.add_argument("--smooth-poly", type=int, default=2)
    parser.add_argument("--gain-threshold", type=float, default=30.0); parser.add_argument("--eps-height", type=float, default=0.3)
    parser.add_argument("--prominence", type=float, default=40.0); parser.add_argument("--peak-edge-km", type=float, default=0.25)
    parser.add_argument("--plot-dpi", type=int, default=150); parser.add_argument("--plot-x-tick-major", type=float, default=5.0); parser.add_argument("--plot-x-tick-minor", type=float, default=1.0)
    parser.add_argument("--pause-min-duration", type=float, default=120.0); parser.add_argument("--pause-max-distance", type=float, default=5.0)
    # TODO: Optional: Argumente für die Offset-Bins/Werte hinzufügen
    args = parser.parse_args()

    config = Config(
        smooth_window=args.smooth_window, 
        # ... (alle anderen config Zuweisungen aus args) ...
        pause_max_distance_m=args.pause_max_distance
        # surface_plot_colors=surface_colors_to_use # Wenn du aus YAML lädst
    )

    main(args, config)